# Video Game Big Data - AnÃ¡lisis con Hadoop, Spark y FastAPI

Sistema de anÃ¡lisis de reseÃ±as de videojuegos utilizando tecnologÃ­as Big Data (HDFS, Spark) con una API REST para consultar los resultados.

## ğŸ“‹ Requisitos Previos

- Docker Desktop instalado y ejecutÃ¡ndose
- Git Bash o WSL (para Windows)
- Al menos 8GB de RAM disponible
- 10GB de espacio en disco

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DENTRO DE DOCKER (VOLUMEN INTERNO)             â”‚
â”‚                                                             â”‚
â”‚  1. HDFS (namenode) â†’ /videogames/Video_Games.json         â”‚
â”‚                           â†“                                 â”‚
â”‚  2. Spark procesa y escribe                                â”‚
â”‚     â†’ shared-data:/data/results.csv (volumen interno)      â”‚
â”‚                           â†“                                 â”‚
â”‚  3. API lee desde shared-data:/data/results.csv            â”‚
â”‚     (mismo volumen, dentro de Docker)                      â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ Solo expone puerto 8000
                            â–¼
                 http://localhost:8000/stats
                     (JSON hacia fuera)
```

## ğŸš€ GuÃ­a de EjecuciÃ³n Paso a Paso

### 1. Clonar el Repositorio

```bash
git clone https://github.com/StalinAM/video-game-bigdata.git
cd video-game-bigdata
```

### 2. Verificar la Estructura del Proyecto

```bash
ls -la
```

DeberÃ­as ver:

```
docker-compose.yml
api/
data/
  â””â”€â”€ Video_Games.json
hadoop/
spark/
  â””â”€â”€ spark_analysis.py
```

### 3. Levantar los Contenedores Docker

```bash
docker-compose up -d
```

Este comando crearÃ¡ y ejecutarÃ¡:

- `namenode` - NameNode de Hadoop (puerto 9870)
- `datanode` - DataNode de Hadoop
- `spark-master` - Nodo maestro de Spark (puerto 8080)
- `spark-worker` - Nodo trabajador de Spark
- `api` - API FastAPI (puerto 8000)

**Verificar que los contenedores estÃ¡n corriendo:**

```bash
docker ps
```

### 4. Esperar a que HDFS Inicie

Espera aproximadamente 30 segundos para que el NameNode estÃ© listo. Puedes verificar el estado en:

- HDFS Web UI: http://localhost:9870
- Spark Master UI: http://localhost:8080

### 5. Copiar el JSON al Contenedor NameNode

```bash
docker cp ./data/Video_Games.json namenode:/tmp/Video_Games.json
```

### 6. Subir el JSON a HDFS

```bash
docker exec -it namenode bash -c "hdfs dfs -mkdir -p /videogames && hdfs dfs -put -f /tmp/Video_Games.json /videogames/"
```

> **Nota:** VerÃ¡s muchos mensajes `INFO sasl.SaslDataTransferClient` durante la carga. Esto es normal y muestra el progreso de la transferencia del archivo de 1.7GB. Espera a que termine (puede tomar 1-2 minutos).

**Verificar que el archivo estÃ¡ en HDFS:**

```bash
docker exec -it namenode bash -c "hdfs dfs -ls /videogames/"
```

DeberÃ­as ver algo como:

```
Found 1 items
-rw-r--r--   1 root supergroup 1702313074 2026-01-13 13:14 /videogames/Video_Games.json
```

### 7. Ejecutar el Job de Spark

```bash
docker exec spark-master /spark/bin/spark-submit /opt/spark-apps/spark_analysis.py
```

**Nota para PowerShell:**

```powershell
docker exec spark-master /spark/bin/spark-submit /opt/spark-apps/spark_analysis.py
```

El script realizarÃ¡:

1. Lectura del JSON desde HDFS
2. AnÃ¡lisis de datos (promedio de puntuaciones por producto)
3. GeneraciÃ³n del CSV en `/data/results.csv` (volumen interno de Docker)

**Salida esperada:**

```
only showing top 10 rows
âœ“ Archivo CSV generado exitosamente en /data/results.csv
```

### 8. Verificar que el CSV fue Generado

```bash
docker exec spark-master head -n 5 /data/results.csv
```

DeberÃ­as ver:

```
asin,avg_score,review_count
B00004SW06,5.0,14
B00002SVBA,5.0,17
...
```

### 9. Probar la API

**Endpoint raÃ­z:**

```bash
curl http://localhost:8000/
```

Respuesta esperada:

```json
{ "message": "API de AnÃ¡lisis de Videojuegos Online" }
```

**Endpoint de estadÃ­sticas:**

```bash
curl http://localhost:8000/stats | head -c 500
```

Respuesta esperada (primeros registros):

```json
[
  {"asin":"B00004SW06","avg_score":5.0,"review_count":14},
  {"asin":"B00002SVBA","avg_score":5.0,"review_count":17},
  ...
]
```

**Abrir en el navegador:**

- API Root: http://localhost:8000
- EstadÃ­sticas: http://localhost:8000/stats
- DocumentaciÃ³n interactiva: http://localhost:8000/docs

## ğŸ”§ Comandos Ãštiles

### Ver logs de un contenedor

```bash
docker logs spark-master --follow
docker logs api --follow
```

### Reiniciar todos los servicios

```bash
docker-compose restart
```

### Detener todos los servicios

```bash
docker-compose down
```

### Eliminar volÃºmenes y empezar desde cero

```bash
docker-compose down -v
docker-compose up -d
```

### Acceder a un contenedor

```bash
docker exec -it spark-master bash
docker exec -it namenode bash
docker exec -it api bash
```

### Ver el estado de HDFS

```bash
docker exec -it namenode bash -c "hdfs dfsadmin -report"
```

## ğŸ“Š Endpoints de la API

| MÃ©todo | Endpoint | DescripciÃ³n                                                 |
| ------ | -------- | ----------------------------------------------------------- |
| GET    | `/`      | Mensaje de bienvenida                                       |
| GET    | `/stats` | EstadÃ­sticas de videojuegos (asin, avg_score, review_count) |
| GET    | `/docs`  | DocumentaciÃ³n interactiva Swagger UI                        |
| GET    | `/redoc` | DocumentaciÃ³n alternativa ReDoc                             |

## ğŸ› SoluciÃ³n de Problemas

### Error: "Cannot connect to Docker daemon"

```bash
# AsegÃºrate de que Docker Desktop estÃ¡ ejecutÃ¡ndose
docker --version
```

### Error: "port is already allocated"

```bash
# Detener contenedores que usen los puertos
docker-compose down
# O cambiar los puertos en docker-compose.yml
```

### Error: "No such file or directory" al ejecutar spark-submit

```bash
# Usar MSYS_NO_PATHCONV=1 en Git Bash
MSYS_NO_PATHCONV=1 docker exec spark-master /spark/bin/spark-submit /opt/spark-apps/spark_analysis.py
```

### La API devuelve "Los datos aÃºn no han sido procesados"

```bash
# Verificar que el CSV existe
MSYS_NO_PATHCONV=1 docker exec spark-master ls -la /data/

# Re-ejecutar el job de Spark
MSYS_NO_PATHCONV=1 docker exec spark-master /spark/bin/spark-submit /opt/spark-apps/spark_analysis.py
```

### HDFS estÃ¡ en modo seguro

```bash
docker exec -it namenode bash -c "hdfs dfsadmin -safemode leave"
```

## ğŸ“ Estructura del Proyecto

```
video-game-bigdata/
â”œâ”€â”€ docker-compose.yml          # ConfiguraciÃ³n de servicios Docker
â”œâ”€â”€ README.md                   # Esta guÃ­a
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ dockerfile             # Imagen Docker de la API
â”‚   â”œâ”€â”€ main.py                # CÃ³digo de la API FastAPI
â”‚   â””â”€â”€ requirements.txt       # Dependencias Python
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Video_Games.json       # Dataset de reseÃ±as (origen)
â”œâ”€â”€ hadoop/
â”‚   â”œâ”€â”€ core-site.xml          # ConfiguraciÃ³n de Hadoop Core
â”‚   â””â”€â”€ hdfs-site.xml          # ConfiguraciÃ³n de HDFS
â””â”€â”€ spark/
    â””â”€â”€ spark_analysis.py      # Script de anÃ¡lisis con PySpark
```

## ğŸ” Detalles TÃ©cnicos

### Procesamiento de Datos con Spark

El script `spark_analysis.py` realiza:

1. **Lectura**: Lee el JSON desde HDFS (`hdfs://namenode:9000/videogames/Video_Games.json`)
2. **Limpieza**: Filtra registros con valores nulos en `asin` y `overall`
3. **AgregaciÃ³n**: Calcula el promedio de puntuaciÃ³n (`avg_score`) y cuenta de reseÃ±as (`review_count`) por producto (`asin`)
4. **Ordenamiento**: Ordena por puntuaciÃ³n descendente
5. **Escritura**: Genera un Ãºnico CSV en el volumen compartido interno

### VolÃºmenes de Docker

- `namenode`: Volumen persistente para metadatos de HDFS
- `datanode`: Volumen persistente para datos de HDFS
- `shared-data`: **Volumen compartido interno** entre `spark-master`, `spark-worker` y `api`
  - **No estÃ¡ montado en el host**
  - Solo los contenedores pueden acceder a Ã©l
  - Permite compartir `results.csv` entre Spark y la API

## ğŸ“ˆ PrÃ³ximos Pasos

- Agregar mÃ¡s anÃ¡lisis (por plataforma, tendencias temporales)
- Implementar cachÃ© en la API
- AÃ±adir tests automatizados
- Configurar CI/CD
- Agregar autenticaciÃ³n a la API

## ğŸ‘¤ Autor

**Stalin Andrade**

- GitHub: [@StalinAM](https://github.com/StalinAM)

## ğŸ“ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo la Licencia MIT.

---

**Â¿Preguntas o problemas?** Abre un issue en GitHub.
